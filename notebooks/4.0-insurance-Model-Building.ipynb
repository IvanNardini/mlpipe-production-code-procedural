{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Fraud Claims Detection\n",
    "\n",
    "In this notebook, I'm going to train the model with engineered data and selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Enviroments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:00.453791Z",
     "start_time": "2020-06-17T13:39:00.435796Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read the data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Data Sciences\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "#Utils\n",
    "import os\n",
    "\n",
    "# Set notebook\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:01.045818Z",
     "start_time": "2020-06-17T13:39:01.041811Z"
    }
   },
   "outputs": [],
   "source": [
    "raw = '../data/raw/insurance_claims.csv'\n",
    "interim = '../data/interim/'\n",
    "processed= '../data/processed/'\n",
    "models= '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:01.524742Z",
     "start_time": "2020-06-17T13:39:01.491747Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(processed + 'data_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:02.072744Z",
     "start_time": "2020-06-17T13:39:02.061746Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv(processed + 'selected_features.csv', header=None, names=['features_selected'])\n",
    "features = list(features['features_selected'])\n",
    "\n",
    "print('Number of features: ', len(features))\n",
    "print('\\n', sorted(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data['fraud_reported'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=1) # ALWAYS set random seed for reproducibility!\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:02.393486Z",
     "start_time": "2020-06-17T13:39:02.383483Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:02.548486Z",
     "start_time": "2020-06-17T13:39:02.542482Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote for balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:02.894236Z",
     "start_time": "2020-06-17T13:39:02.856247Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts()/len(y_train), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T10:32:42.581493Z",
     "start_time": "2020-06-17T10:32:42.578482Z"
    }
   },
   "source": [
    "#### Smote for balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:03.395191Z",
     "start_time": "2020-06-17T13:39:03.349162Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=9)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntetic Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_syn.value_counts()/len(y_train_syn), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:04.118945Z",
     "start_time": "2020-06-17T13:39:04.114946Z"
    }
   },
   "outputs": [],
   "source": [
    "model_predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:47.149394Z",
     "start_time": "2020-06-17T13:39:46.978403Z"
    }
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=8)\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "predictions = logit.predict(X_test)\n",
    "\n",
    "print()\n",
    "print(\"*\"*20)\n",
    "print(\"Model Assessment\".center(20, '*'))\n",
    "print(\"*\"*20)\n",
    "\n",
    "predictions = logit.predict(X_test)\n",
    "print('score: {}'.format(round(logit.score(X_test, y_test), 3)))\n",
    "print()\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Confusion Matrix')\n",
    "conf_matrix = confusion_matrix(predictions, y_test)\n",
    "plot_confusion_matrix(conf_matrix);\n",
    "\n",
    "tpr, fpr, threshold = roc_curve(predictions, y_test, pos_label=1)\n",
    "model_predictions[\"Logistic Regression\"] = [tpr, fpr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:39:55.763463Z",
     "start_time": "2020-06-17T13:39:55.537292Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC(random_state=8)\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "predictions = svc.predict(X_test)\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"Model Assessment\".center(20, '*'))\n",
    "print(\"*\"*20)\n",
    "\n",
    "predictions = svc.predict(X_test)\n",
    "print('score: {}'.format(round(svc.score(X_test, y_test), 3)))\n",
    "print()\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Confusion Matrix')\n",
    "conf_matrix = confusion_matrix(predictions, y_test)\n",
    "plot_confusion_matrix(conf_matrix);\n",
    "\n",
    "tpr, fpr, threshold = roc_curve(predictions, y_test, pos_label=1)\n",
    "model_predictions[\"SVM\"] = [tpr, fpr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:40:02.824630Z",
     "start_time": "2020-06-17T13:40:02.697601Z"
    }
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=8)\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "predictions = dtree.predict(X_test)\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"Model Assessment\".center(20, '*'))\n",
    "print(\"*\"*20)\n",
    "\n",
    "predictions = dtree.predict(X_test)\n",
    "print('score: {}'.format(round(dtree.score(X_test, y_test), 3)))\n",
    "print()\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Confusion Matrix')\n",
    "conf_matrix = confusion_matrix(predictions, y_test)\n",
    "plot_confusion_matrix(conf_matrix);\n",
    "\n",
    "tpr, fpr, threshold = roc_curve(predictions, y_test, pos_label=1)\n",
    "model_predictions[\"Decision Tree\"] = [tpr, fpr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:40:09.074646Z",
     "start_time": "2020-06-17T13:40:08.725649Z"
    }
   },
   "outputs": [],
   "source": [
    "rfor = RandomForestClassifier(random_state=8)\n",
    "\n",
    "rfor.fit(X_train, y_train)\n",
    "predictions = rfor.predict(X_test)\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"Model Assessment\".center(20, '*'))\n",
    "print(\"*\"*20)\n",
    "\n",
    "print('score: {}'.format(round(rfor.score(X_test, y_test), 3)))\n",
    "print()\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Confusion Matrix')\n",
    "conf_matrix = confusion_matrix(predictions, y_test)\n",
    "plot_confusion_matrix(conf_matrix);\n",
    "\n",
    "tpr, fpr, threshold = roc_curve(predictions, y_test, pos_label=1)\n",
    "model_predictions[\"Random Forest\"] = [tpr, fpr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:40:14.886083Z",
     "start_time": "2020-06-17T13:40:14.595084Z"
    }
   },
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state=8)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "predictions = lgbm.predict(X_test)\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"Model Assessment\".center(20, '*'))\n",
    "print(\"*\"*20)\n",
    "\n",
    "predictions = lgbm.predict(X_test)\n",
    "print('score: {}'.format(round(lgbm.score(X_test, y_test), 3)))\n",
    "print()\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Confusion Matrix')\n",
    "conf_matrix = confusion_matrix(predictions, y_test)\n",
    "plot_confusion_matrix(conf_matrix);\n",
    "\n",
    "tpr, fpr, threshold = roc_curve(predictions, y_test, pos_label=1)\n",
    "model_predictions[\"LightGBM\"] = [tpr, fpr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:40:17.025669Z",
     "start_time": "2020-06-17T13:40:16.844631Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.title(\"ROC curves\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "for key, value in model_predictions.items():\n",
    "    model_list = model_predictions[key]\n",
    "    plt.plot(model_list[0], model_list[1], label=key)\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:02:33.399051Z",
     "start_time": "2020-06-17T12:49:06.989278Z"
    }
   },
   "outputs": [],
   "source": [
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "hyper = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "grid = GridSearchCV(rfor, hyper, cv = 3, verbose = 1, n_jobs = -1)\n",
    "best = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:05:48.726304Z",
     "start_time": "2020-06-17T13:05:48.718297Z"
    }
   },
   "outputs": [],
   "source": [
    "best.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T13:40:31.507458Z",
     "start_time": "2020-06-17T13:40:30.255461Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfor_tune = RandomForestClassifier(max_depth=25, min_samples_split=5, n_estimators=300,\n",
    "                       random_state=8)\n",
    "\n",
    "rfor_tune.fit(X_train, y_train)\n",
    "predictions = rfor_tune.predict(X_test)\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"Model Assessment\".center(20, '*'))\n",
    "print(\"*\"*20)\n",
    "\n",
    "predictions = rfor_tune.predict(X_test)\n",
    "print('score: {}'.format(round(rfor_tune.score(X_test, y_test), 2)))\n",
    "print()\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Confusion Matrix')\n",
    "conf_matrix = confusion_matrix(predictions, y_test)\n",
    "plot_confusion_matrix(conf_matrix);\n",
    "\n",
    "tpr, fpr, threshold = roc_curve(predictions, y_test, pos_label=1)\n",
    "model_predictions[\"Random Forest Tuned\"] = [tpr, fpr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is the **Random Forest** with a score of **0.89**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
